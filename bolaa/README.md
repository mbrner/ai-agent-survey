<!--- Created using: ... --->
<!--- Based on: 100.0% of the Paper --->
<!--- Reviewed: False --->
# BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents

**Relevance: ...**

**Link**:
- Paper: [Arxiv](http://arxiv.org/pdf/2308.05960v1)
- Code: N/A

**Authors**: Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, Rithesh Murthy, Yihao Feng, Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit, Ran Xu, Phil Mui, Huan Wang, Caiming Xiong, Silvio Savarese

## Summary

**TL;DR: The paper explores Large Language Model-augmented Autonomous Agents (LAAs), introducing a novel strategy (BOLAA) for managing multiple LAAs, and demonstrates that the BOLAA architecture outperforms others in complex tasks, with the best performance observed with Llama-2-70b, suggesting the potential of fine-tuning multiple smaller-sized specialised LAAs and the importance of pairing the LLM with the optimal LAA architecture.**

The paper systematically investigates Large Language Model-augmented Autonomous Agents (LAAs), comparing various agent architectures and LLM backbones. It acknowledges the rise of applications like HuggingGPT, Generative Agents, WebGPT, AutoGPT, BabyAGI, and Langchain, and the potential of aligning the optimal architecture of agents with tasks and the corresponding LLM backbone. The paper also introduces the 'Tool Agent' concept and the use of LLMs to enhance their capabilities and solve complex tasks.

### Approach

The authors introduce a novel strategy, BOLAA, to manage multiple LAAs, each focusing on a specific type of action, with a controller overseeing their communication. The controller constructs the message for the selected LAA and builds the communication, then parses the response to an executable action and interacts with the environment. The paper evaluates the effectiveness of LAAs in decision-making and multi-step reasoning environments, and advocates for a deeper understanding of the effectiveness of existing LLMs in LAAs. It references methods such as Chain-of-Thoughts (CoT) and ReAct for deconstructing complex tasks and fostering interactive engagement with the environment. The paper also explores the use of environment rewards to enhance agent behaviors, as seen in Self-refine, REX, RAP, Reflexion, and Retroformer. Additionally, it presents the LAA architectures for Zeroshot-LAA (ZS-LAA), ZeroshotThink LAA (ZST-LAA), ReAct LAA, and PlanAct LAA, each with its own interaction strategy and unique features.

### Results

The paper underscores the importance of selecting optimal LLMs from both efficacy and efficiency perspectives to advance the exploration of LAAs. It notes that the increasing complexity of tasks may necessitate the orchestration of multiple agents, especially in open-domain environments. The BOLAA architecture consistently outperforms other LAA architectures in the WebShop environment, demonstrating the importance of designing specialist agents to collaborate on complex tasks. It also provides a detailed description of the working flow of ZS-LAA, ZST-LAA, and ReAct LAA, which directly extends the LLM to be an action executor, and introduces the concept of 'self-think' steps and fewshot examples in the prompt layer. The paper also evaluates LAAs in the HotPotQA environment, a multi-hop question answering task that requires reasoning over multiple Wikipedia passages. The evaluation metrics include the reward score in each environment and the Recall performance for the WebShop environment. The paper also compares different LLMs with various choices of model size and context length, including fastchat-3b, vicuna-3b/13b/33b, Llama-2-7b/13b/70b6, MPT-7b/30b, xgen-8k-7b, longchat-16k-7b/13b and OpenAI API LLMs, such as text-davinci-003, gpt-3.5-turbo and gpt-3.5-turbo-16k. The paper also highlights the relationship between recall performance and reward performance, noting that high recall performance does not necessarily lead to high reward performance. It also observes that the BOLAA model consistently performs better across all LLMs and complexity levels, indicating that separating the search agent from the click agent improves the accuracy of the search action, leading to a higher recall value. In the HotPotQA environment, the ReAct agent architecture achieves the best performances, indicating that fewshot prompts are necessary to enable action generation and reasoning ability for LAAs. The paper also notes that the planning flow of LAA hinders performance in knowledge reasoning tasks, as these tasks require contextualized information for reasoning, which the planning flow, executed ahead of interactions, tends to hallucinate. It also highlights that model size is more important than context length for knowledge reasoning tasks, with larger models performing better. The superior reasoning ability of OpenAI gpt-3.5 models is again verified, and the best performance of all open-source LLMs is observed with Llama-2-70b, suggesting potential for future fine-tuning on Llama-2 models. The paper also observes a degradation in performance with increasing task complexity. However, the Llama-2-70b model demonstrates comparable reasoning ability with the OpenAI text-davinci-003 model, especially in hard questions, indicating its potential in handling complex tasks.

### Conclusion

The paper concludes by emphasizing the need for further research into orchestrating multiple agents and the impacts of such orchestration. It suggests that as task complexity increases, coordinating multiple agents to complete a single task may be more efficient. The paper's contributions include the development of six different LAA agent architectures and extensive experiments on decision-making web navigation and knowledge reasoning task environments. It also highlights the importance of incorporating feedback mechanisms, such as environment rewards, to enhance agent behaviors. The superiority of BOLAA indicates that orchestrating multiple smaller-sized LAAs is a better choice if the computing resources are limited. This further exemplifies the potential for fine-tuning multiple smaller-sized specialised LAAs rather than fine-tuning one large generalized LAA. Pairing the LLM with the optimal LAA architecture is crucial. For example, Llama-2-13b performs best under PlanAct LAA arch while Llama-2-70b performs best under the BOLAA arch. Also, Longchat-13b-16K performs best when using PlanAct and PlanReAct, which may indicate the extraordinary planning ability of longchat-13b-16k models. Increasing the context length alone may not necessarily improve the LAA performances. For example, when comparing longchat-13b-16k with llama-2-13b models, the latter yields better performances though with less context length. The paper also highlights that a powerful LLM can generalize under the zeroshot LAA arch, and that the best performance of OpenAI API-based models are actually under ZS and ZST arch. This indicates the great potential of developing a generic LAA with powerful LLM, and that using only a ZS LAA can already achieve comparable or even better performances than LAA arch with additional Plan or Self-think flow. However, for other less powerful LLMs, fewshot prompts are necessary for LAAs. The paper also identifies the challenge of designing BOLAA architecture for environments with compounding actions and suggests future exploration of harnessing LLMs in the controller for fully autonomous selection and communication with labor agents.

## Implications/Learnings for GPT4Hana

...
