<!--- Created using: gpt-4 --->
<!--- Reviewed: False --->
# Tree of Thoughts: Deliberate Problem Solving with Large Language Models

**Link**: [Paper](http://arxiv.org/pdf/2305.10601v1)
**Authors**: Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan

## Summary

**TL;DR: The 'Tree of Thoughts' (ToT) framework is a novel approach to problem-solving with Language Learning Models (LLMs), enabling more deliberate decision-making and strategic planning, and demonstrating superior performance on challenging tasks, while also improving the interpretability of model decisions and offering potential for future applications.**

Language models, such as GPT and PaLM, have been increasingly used for problem-solving across various tasks, including those requiring mathematical, symbolic, commonsense, and knowledge reasoning. However, their current inference methods, which are confined to token-level, left-to-right decision-making processes, can fall short in tasks that require exploration, strategic lookahead, or where initial decisions are crucial. Drawing inspiration from the literature on human cognition, 'dual process' models, and the planning processes explored by Newell, Shaw, and Simon in the 1950s, the authors propose a new framework for language model inference, 'Tree of Thoughts' (ToT). This framework generalizes the 'Chain of Thought' approach to prompting language models and allows for exploration over coherent units of text ('thoughts') that serve as intermediate steps towards problem-solving. ToT enables language models to perform deliberate decision-making by considering multiple reasoning paths, self-evaluating choices, and making global choices by looking ahead or backtracking when necessary.

### Approach

The 'Tree of Thoughts' (ToT) framework is illustrated through various approaches to problem-solving with Language Learning Models (LLMs). Each 'thought', represented as a rectangle box, is a coherent language sequence that serves as an intermediate step towards problem-solving. The ToT framework allows the model to generate, evaluate, and search through these 'thoughts'. The model can self-evaluate the progress different intermediate thoughts make towards solving the problem through a deliberate reasoning process. This implementation of search heuristics via LM self-evaluation and deliberation is novel, as previous search heuristics are either programmed or learned. The authors also combine this language-based capability to generate and evaluate diverse thoughts with search algorithms, such as breadth-first search (BFS) or depth-first search (DFS), which allow systematic exploration of the tree of thoughts with lookahead and backtracking. The authors further elaborate on two strategies for evaluating states: valuing each state independently or voting across states. These strategies can be prompted multiple times to aggregate the value or vote results, trading time/resource/cost for more faithful/robust heuristics.
### Results

The authors propose three new problems that challenge existing LM inference methods even with the state-of-the-art language model, GPT-4: Game of 24, Creative Writing, and Crosswords. These tasks require deductive, mathematical, commonsense, lexical reasoning abilities, and a way to incorporate systematic planning or search. The ToT framework obtains superior results on all three tasks by being general and flexible enough to support different levels of thoughts, different ways to generate and evaluate thoughts, and different search algorithms that adapt to the nature of different problems. The authors also analyze how such choices affect model performances via systematic ablations. In the Game of 24, a mathematical reasoning challenge, the ToT framework was tested on a subset of relatively hard games. The success of the model was measured by its ability to generate a valid equation that equals 24 using the input numbers each exactly once. The ToT setup for the Game of 24 involved decomposing the thoughts into 3 steps, each an intermediate equation. A breadth-first search (BFS) was performed in ToT, keeping the best 5 candidates at each step. The model was prompted to evaluate each thought candidate as 'sure/maybe/impossible' with regard to reaching 24, promoting correct partial solutions and eliminating impossible ones. The ToT framework achieved a success rate of 74% on the Game of 24, significantly outperforming other methods such as IO, CoT, and CoT-SC which only achieved success rates of 7.3%, 4.0%, and 9.0% respectively. Additionally, the ToT framework was found to generate more coherent passages than IO and CoT, with an average GPT-4 score of 7.56 across 100 tasks, compared to 6.19 for IO and 6.93 for CoT. Human evaluators also preferred ToT over CoT in 41 out of 100 passage pairs. In the Creative Writing task, the ToT framework improved the IO coherency score from 6.19 to 7.67, and the ToT coherency score from 7.56 to 7.91. In the Mini Crosswords task, the ToT framework achieved a success rate of 78%, significantly outperforming other methods. The task involved solving 5x5 mini crosswords, a more complex problem that required the model to explore its own thoughts and guide its own exploration with deliberate reasoning as heuristics. The ToT framework uses a depth-first search (DFS) for the Mini Crosswords task, with thoughts proposed and aggregated in a priority queue. Each state is evaluated based on the possibility of filling in each remaining word clue, and pruned if any remaining clue is deemed not possible to fill by the LM. The DFS then backtracks to the parent state and explores the next promising thought. The ToT framework significantly improved all metrics in the Mini Crosswords task, achieving a word-level success rate of 60% and solving 4 out of 20 games. Oracle and ablation studies showed that when outputting from the oracle best DFS state, ToT performance is even higher, solving 7 out of 20 games. This indicates that the simple output heuristics can be readily improved. However, the state evaluation as a pruning heuristic is imperfect, and better heuristics for DFS pruning are critical for problem solving. An ablation study that keeps filling the most promising clue for at most 20 steps, allowing overwrites, performed poorly with a word level success of only 20%.
## Conclusion

The 'Tree of Thoughts' (ToT) framework provides a novel approach to problem-solving with Language Learning Models (LLMs), allowing for more deliberate decision-making and strategic planning. The framework's flexibility and adaptability to different problems and reasoning abilities have been demonstrated through its superior performance on three challenging tasks. Future directions include further exploration of how to better train and use LMs within this framework, particularly focusing on the decomposition of the intermediate process into thought steps, the generation of potential thoughts from each state, the heuristic evaluation of states, and the choice of search algorithm. The ToT framework has several benefits including generality, modularity, adaptability, and convenience. It can accommodate different problem properties, LM capabilities, and resource constraints, and requires no extra training, just a pre-trained LM. The ToT approach extends existing planning formulations by considering multiple potentially feasible plans simultaneously at each problem-solving step, and proceeding with the most promising ones. The integration between thought sampling and value feedback organically integrates planning and decision-making mechanisms, enabling effective search inside a solution tree. Unlike traditional decision-making procedures that usually require training dedicated reward and policy models, the ToT framework uses the LM itself to provide the value estimates for decision making. The ToT framework is more versatile than other methods, such as self-eval decoding, as it can handle challenging tasks that GPT-4 struggles with using standard prompts. It also differs from other program-guided LLM generation methods by expanding trees with the LM's own thoughts rather than external paragraphs, and includes reflection or voting steps. The ToT framework can be seen as a modern rendition of classical search methods for problem-solving, with the heuristic at each search node provided by the LM's self-assessment. However, it's worth noting that while ToT requires more resources than sampling methods, its modular flexibility allows users to customize performance-cost tradeoffs. Future work could explore fine-tuning LMs using a ToT-style high-level counterfactual decision making, which might enhance the problem-solving capabilities of LMs. The ToT framework also has broader impacts, as it empowers LMs to more autonomously and intelligently make decisions and solve problems. While current tasks are limited to reasoning and search problems, future applications involving interaction with external environments or humans could bring potential danger, e.g. facilitating harmful uses of LMs. On the other hand, ToT also improves the interpretability of model decisions and the opportunity for human alignment, as the resulting representations are readable, high-level language reasoning instead of implicit, low-level token values. The associative “System 1” of LMs can be beneﬁcially augmented by a “System 2” based on searching a tree of possible paths to the solution to a problem. The Tree of Thoughts framework provides a way to translate classical insights about problem-solving into actionable methods for contemporary LMs. At the same time, LMs address a weakness of these classical methods, providing a way to solve complex problems that are not easily formalized, such as creative writing. We see this intersection of LMs with classical approaches to AI as an exciting direction for future work.
